# Data Directory

This directory contains the Deezer Sequential Skip Prediction dataset and processed outputs.

## ğŸ“ Structure

```
data/
â”œâ”€â”€ raw/                    # Original dataset (not in git)
â”‚   â”œâ”€â”€ train.csv          # 7.5M training interactions
â”‚   â””â”€â”€ test.csv           # Test set
â”‚
â”œâ”€â”€ processed/             # Processed data (not in git, except metadata)
â”‚   â”œâ”€â”€ samples/          # Sample datasets for development
â”‚   â”‚   â”œâ”€â”€ cf_sample_500k.csv (33.5 MB)
â”‚   â”‚   â”œâ”€â”€ cf_sample_info.txt
â”‚   â”‚   â”œâ”€â”€ create_cf_sample_random.py
â”‚   â”‚   â””â”€â”€ create_cf_sample.py
â”‚   â”‚
â”‚   â”œâ”€â”€ preprocessing/    # Preprocessed features
â”‚   â”‚   â”œâ”€â”€ train_preprocessed_sample.csv
â”‚   â”‚   â”œâ”€â”€ test_preprocessed_sample.csv
â”‚   â”‚   â””â”€â”€ user_stats_from_train.csv
â”‚   â”‚
â”‚   â”œâ”€â”€ eda/             # EDA outputs
â”‚   â”‚   â”œâ”€â”€ user_segments.csv
â”‚   â”‚   â””â”€â”€ temporal_inconsistencies_sample.csv
â”‚   â”‚
â”‚   â””â”€â”€ collaborative_filtering_results.csv
â”‚
â”œâ”€â”€ README.md             # This file
â”œâ”€â”€ DATA_QUALITY_REPORT.txt
â”œâ”€â”€ DATA_QUALITY_SUMMARY.md
â””â”€â”€ TEMPORAL_CONSISTENCY_ANALYSIS.md
```

---

## ğŸ“Š Dataset Information

**Source**: Deezer Research - DSG17 Dataset  
**Task**: Sequential Skip Prediction  
**Size**: ~7.5M training interactions, 19.9K users, 451K tracks

### Raw Data Features
- `user_id` - Unique user identifier
- `media_id` - Unique track identifier
- `is_listened` - Target (1 = listened, 0 = skipped)
- `timestamp` - Listening timestamp
- `release_date` - Track release date
- `ts_listen` - Precise listening timestamp
- `duration` - Track duration (seconds)
- `user_age`, `user_gender` - Demographics
- `album_id`, `artist_id`, `genre_id` - Content IDs
- `context_type`, `platform_name` - Listening context

---

## ğŸ”„ Processed Data

### `/processed/samples/` - Development Samples

**`cf_sample_500k.csv`** â­ Main sample
- 500,000 random interactions (seed=42)
- 18,558 users (93.2% coverage)
- 105,803 tracks (23.4% coverage)
- Perfect for quick experiments

**Creation scripts**: `create_cf_sample_random.py`, `create_cf_sample.py`

### `/processed/preprocessing/` - Feature Engineering

**`train_preprocessed_sample.csv`** - Training with 31 features
**`test_preprocessed_sample.csv`** - Test with 31 features
**`user_stats_from_train.csv`** - User statistics lookup

Features added:
- 9 temporal features
- 7 release features
- 3 duration features
- 9 user engagement features (computed from train only)

### `/processed/eda/` - Analysis Outputs

**`user_segments.csv`** - 19,165 users with skip behavior segments
**`temporal_inconsistencies_sample.csv`** - Pre-release listening events

---

## ğŸš« .gitignore Policy

**Excluded from Git** (too large):
- `data/raw/*` - Original dataset
- `data/processed/*` - All processed data files

**Included in Git** (metadata only):
- `*.md` - Documentation
- `*.txt` - Metadata and info files
- `create_*.py` - Data creation scripts

---

## ğŸ“¥ Data Access

### Raw Data
Download from Deezer Research or obtain from project collaborators.

Place in:
```
data/raw/train.csv
data/raw/test.csv
```

### Processed Data
Generated by scripts in `notebooks/`:
- EDA outputs: Run `notebooks/01_eda/*.py`
- Samples: Run `data/processed/samples/create_cf_sample_random.py`
- Preprocessing: Run `notebooks/02_preprocessing/*.py`

---

## ğŸ“Š Quick Stats

### Raw Dataset
- **Training**: 7,560,023 interactions
- **Users**: 19,914 unique
- **Tracks**: 451,867 unique
- **Listen rate**: 68.4%
- **Skip rate**: 31.6%

### Sample Dataset (500K)
- **Interactions**: 500,000 (6.6% of full)
- **Users**: 18,558 (93.2% coverage)
- **Tracks**: 105,803 (23.4% coverage)
- **Listen rate**: 68.4% (matches full dataset)

---

## ğŸ”§ Usage

### Load Raw Data
```python
import pandas as pd

train_df = pd.read_csv('data/raw/train.csv')
test_df = pd.read_csv('data/raw/test.csv')
```

### Load Sample
```python
sample_df = pd.read_csv('data/processed/samples/cf_sample_500k.csv')
```

### Load Preprocessed
```python
train_processed = pd.read_csv('data/processed/preprocessing/train_preprocessed_sample.csv')
user_stats = pd.read_csv('data/processed/preprocessing/user_stats_from_train.csv')
```

---

## ğŸ“š Documentation

- `DATA_QUALITY_REPORT.txt` - Complete data quality analysis
- `DATA_QUALITY_SUMMARY.md` - Summary of quality checks
- `TEMPORAL_CONSISTENCY_ANALYSIS.md` - Temporal pattern analysis
- `notebooks/docs/` - Additional documentation

---

**Note**: All large data files are excluded from Git. Generate them using the scripts in `notebooks/` or obtain from collaborators.
